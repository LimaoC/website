<!doctype html><html lang=en-au dir=ltr><head><meta charset=utf-8><meta name=viewport content="width=device-width"><link rel=icon type=image/ico href=https://limaoc.dev/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://limaoc.dev/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://limaoc.dev/favicon-32x32.png><link rel=icon type=image/png sizes=192x192 href=https://limaoc.dev/android-chrome-192x192.png><link rel=apple-touch-icon sizes=180x180 href=https://limaoc.dev/apple-touch-icon.png><meta name=description content><title>Nesterov's Accelerated Gradient Descent Method | Limao Chang</title><link rel=canonical href=https://limaoc.dev/projects/nesterov-agd/><meta property="og:url" content="https://limaoc.dev/projects/nesterov-agd/"><meta property="og:site_name" content="Limao Chang"><meta property="og:title" content="Nesterov's Accelerated Gradient Descent Method"><meta property="og:description" content="A tutorial paper on Nesterov’s AGD method"><meta property="og:locale" content="en_au"><meta property="og:type" content="article"><meta property="article:section" content="projects"><meta property="article:published_time" content="2024-05-06T00:00:00+00:00"><meta property="article:modified_time" content="2024-05-06T00:00:00+00:00"><meta property="article:tag" content="Machine Learning"><meta property="article:tag" content="Numerical Optimisation"><link rel=stylesheet href=/assets/combined.min.92c3bf7119b98cfdc79e93f36a451eb901d8bbbfed7d75814e6436cf6c9085dc.css media=all></head><body class=auto><div class=content><header><div class=header><h1 class=header-title><a href=https://limaoc.dev/>Limao Chang</a></h1><div class=header-menu><p class=small><a href=/>/home</a></p><p class=small><a href=/projects>/projects</a></p><p class=small><a href=/resume>/resume</a></p><p class=small><a href=/tags>/tags</a></p></div></div></header><main class=main><div class=breadcrumbs><a href=/>~</a><span class=breadcrumbs-separator>/</span><a href=/projects/>Projects</a><span class=breadcrumbs-separator>/</span>
<a href=/projects/nesterov-agd/>Nesterov's Accelerated Gradient Descent Method</a></div><div><article><header class=single-intro-container><h1 class=single-title>Nesterov's Accelerated Gradient Descent Method</h1><p class=single-summary>A tutorial paper on Nesterov&rsquo;s AGD method</p><div class=single-subsummary><div><p class=single-date><time datetime=2024-05-06T00:00:00+00:00>May 6, 2024</time>
&nbsp; · &nbsp;1 min read</p></div></div></header><div class=single-content><p>Nesterov&rsquo;s Accelerated Gradient Descent (AGD) method is a variant of gradient descent that incorporates acceleration- and momentum-based concepts to overcome the limitations found in its classical counterpart. In this tutorial paper, we will provide an intution introduction to the classical GD and momentum methods, see how they are incorporated into AGD, and compare how they perform against AGD on some toy problems. This is a tutorial paper that I wrote in <a href="https://programs-courses.uq.edu.au/course.html?course_code=stat3007">STAT3007</a> in 2024 Semester 1.</p><hr><ul><li><a href=/projects/nesterov-agd-tute-paper/tutorial.pdf target=_blank>Tutorial paper</a></li></ul></div></article><div class=single-pagination><hr><div class=flexnowrap><div class=single-pagination-prev><div class=single-pagination-container-prev><div class=single-pagination-text>←</div><div class=single-pagination-text><a href=/projects/generalized-jackson-sim.jl/>GeneralizedJacksonSim.jl</a></div></div></div><div class=single-pagination-next><div class=single-pagination-container-next><div class=single-pagination-text><a href=/projects/drosophila-classification/>Drosophila Classification</a></div><div class=single-pagination-text>→</div></div></div></div><hr></div><div class=back-to-top><a href=#top>back to top</a></div></div></main></div><footer><p>© 2025 Limao Chang</p></footer></body><script src=/js/theme-switch.js></script><script defer src=/js/copy-code.js></script></html>